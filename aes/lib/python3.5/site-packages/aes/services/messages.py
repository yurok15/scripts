import math
import logging

from aes.core.sentry import sentry_client
from aes.core.controller import BaseService
from aes.services.elastic_search import ElasticSearchService, modify_date
from aes.services.cluster.service import ClusterService
from aes.services.web.service import WebService
from aes.services.web.base_app import BaseApp

logger = logging.getLogger(__name__)


def modify_size(hit, key_kb, new_key):
    size = hit.get(key_kb, 0)
    if size < 1024:
        hit[new_key] = "%d Kb" % size
    else:
        hit[new_key] = "%.1f Mb" % (size / 1024)


class MessagesService(BaseService, BaseApp):
    app_name = 'messages'
    js = []
    css = []
    menu = {
        'label': 'Messages',
        'url': '/messages',
    }
    es = None
    cluster = None

    def requires(self, es: ElasticSearchService, web: WebService,
                 cluster: ClusterService):
        web.add_app(self)
        self.es = es
        self.cluster = cluster

    async def build_query(self, request):
        data = await request.json()
        requirements = []
        to_filter = data.get('to')
        from_filter = data.get('from')
        id_filter = data.get('id')
        if to_filter:
            if '@' not in to_filter:
                to_filter = '*' + to_filter + '*'
            requirements.append({'wildcard': {'usr_mail_to': to_filter}})
        if from_filter:
            if '@' not in from_filter:
                from_filter = '*' + from_filter + '*'
            requirements.append({'wildcard': {'usr_mail_from': from_filter}})
        body = {
            "query": {
                "bool": {
                    "must": [
                        {"match": {"message": "Message_processed"}},
                        {"match": {"logger_name": "analytics"}},
                        {
                            "range": {
                                "@timestamp": {
                                    "gte": "now-%s" % data['time']
                                }
                            }
                        }
                    ] + requirements,
                    "should": [],
                    "minimum_should_match": 0,
                }
            }
        }
        query_type = data.get('query') or 'all'
        if query_type == 'error':
            body['query']['bool']['must'].append(
                {"match": {"delivery": "error"}},
            )
        elif query_type == 'deny':
            body['query']['bool']['must'].append(
                {"match": {"delivery": "deny"}},
            )
        elif query_type == 'quarantine':
            body['query']['bool']['should'] += [
                {"exists": {"field": "delivery_relay.path"}},
                {"exists": {"field": "quarantine_relay.path"}},
            ]
            body['query']['bool']['minimum_should_match'] += 1
        if id_filter:
            id_filter = '*' + id_filter + '*'
            body['query']['bool']['should'] += [
                {'wildcard': {'usr_message_id': id_filter}},
                {'wildcard': {'usr_client_mail_id': id_filter}},
            ]
            body['query']['bool']['minimum_should_match'] += 1
        return body

    async def query_aggs(self, request, time=None):
        body = await self.build_query(request)
        data = await request.json()
        body['aggregations'] = {
            'timeline': {
                'date_histogram': {
                    'field': '@timestamp',
                    'interval': time or 'day',
                    'min_doc_count': 0,
                    'extended_bounds': {
                        'min': "now-%s" % data['time'],
                        'max': 'now',
                    }
                }
            },
            'senders': {
                'terms': {
                    'field': 'usr_from_domain',
                    'size': 10,
                }
            },
            'recipients': {
                'terms': {
                    'field': 'usr_to_domain',
                    'size': 10,
                }
            }
        }
        body['size'] = 0
        response = await self.es.search(self.es.indexes['analytics'], body)
        timeline = response['aggregations']['timeline']['buckets']
        return {
            'graph': [
                {
                    'key': 'Messages',
                    'values': [{
                        'label': v['key'],
                        'value': v['doc_count']
                    } for v in timeline]
                }
            ],
            'recipients': response['aggregations']['recipients']['buckets'],
            'senders': response['aggregations']['senders']['buckets']
        }

    @staticmethod
    def _get_path(source, param1, param2):
        if param1 not in source:
            return False
        source = source[param1]
        if not isinstance(source, dict):
            return False
        return source.get(param2)

    async def query(self, request, page):
        body = await self.build_query(request)
        data = await request.json()
        sender_domains = data.get('sender_domains')
        recipient_domains = data.get('recipient_domains')
        if sender_domains:
            body['query']['bool']['must'].append(
                {"terms": {"usr_from_domain": sender_domains}}
            )
        if recipient_domains:
            body['query']['bool']['must'].append(
                {"terms": {"usr_to_domain": recipient_domains}}
            )
        body['sort'] = [
            {data.get('sort_field') or '@timestamp': {
                'order': data.get('sort_direction') or 'desc'
            }},
        ]
        page_size = 15
        body['from'] = (int(page) - 1) * 15
        body['size'] = page_size
        response = await self.es.search(self.es.indexes['analytics'], body)
        hits = response['hits']['hits']
        for hit in hits:
            source = hit.get('_source', {})
            hit.update(source)
            hit['time'] = modify_date(hit.get('@timestamp'))
            modify_size(hit, 'out_size_kb', 'size')
            d_path = bool(self._get_path(hit, 'delivery_relay', 'path'))
            q_path = bool(self._get_path(hit, 'quarantine_relay', 'path'))
            hit['can_release'] = d_path or q_path
            hit['can_unloop'] = bool(
                hit.get('delivery') == 'error' and
                hit.get('usr_client_mail_id')
            )
        pages = math.ceil(response['hits']['total'] / page_size)
        return {
            'list': hits,
            'pages': pages,
            'total': response['hits']['total']
        }

    async def unloop_message(self, request, message_id):
        state = 'success'
        text = 'Marked to pass loop check'
        try:
            await self.cluster.make_request(
                'unloop_message', message_id=message_id
            )
        except Exception as e:
            sentry_client.captureException()
            logger.exception(e)
            state = 'error'
            text = str(e)
        return {'state': state, 'text': text}

    async def get_message_info(self, request, message_id):
        body = {
            "query": {
                "bool": {
                    "must": [
                        {"match": {"usr_message_id": message_id}},
                        {"match": {"logger_name": 'analytics'}},

                    ],
                }
            }
        }
        response = await self.es.search(self.es.indexes['analytics'], body)
        attachments = []
        message = {}
        for hit in response['hits']['hits']:
            source = hit.pop('_source', None) or {}
            hit.update(source)
            msg = hit.get('message')
            if msg == 'Message_processed':
                hit['time'] = modify_date(hit.get('@timestamp'))
                modify_size(hit, 'out_size_kb', 'out_size')
                modify_size(hit, 'in_size_kb', 'in_size')
                message = hit
            elif msg == 'attachment':
                modify_size(hit, 'content_size_kb', 'content_size')
                attachments.append(hit)
        body = {
            "query": {
                "bool": {
                    "must": [
                        {"match": {"usr_message_id": message_id}},
                    ],
                }
            },
            'sort': [
                {'@timestamp': {'order': 'desc'}},
            ],
            'size': 100,
        }
        response = await self.es.search(self.es.indexes['logs'], body)
        logs = response['hits']['hits']
        for hit in logs:
            source = hit.pop('_source', None) or {}
            hit.update(source)
            hit['time'] = modify_date(hit.get('@timestamp'))
            del hit['_score']
            del hit['_index']
            del hit['_id']
        return {'message': message, 'attachments': attachments, 'logs': logs}

from base64 import b64encode as encode_b64
from quopri import encodestring as encode_q
from urllib.parse import unquote, urlparse

from aes.filters.base import BaseFilter
from aes.filters.base_actions import AdminQuarantineDelivery
from aes.core.exceptions import ImproperlyConfigured
from aes.message import MessageInfo, Category, SkipFlags
from aes.lib.mime import encoding_aliases, encode_uu
from aes.lib.encoders import AESEncoder
from .utils import template_to_expression
from .searchers import PlainTextSearcher, HtmlSearcher, LinksLimitExceeded

LINKS_LIMIT = 1000


class UrlProtectionFilter(BaseFilter):
    allow_multiple_policy = True
    skip_flag = SkipFlags.URL_PROTECTION
    actions = {
        'admin_quarantine': AdminQuarantineDelivery(
            'url_protection', Category.ERROR),
    }
    default_action = 'admin_quarantine'

    def __init__(self, name, controller, config, loop):
        super(UrlProtectionFilter, self).__init__(
            name, controller, config, loop)
        self.resolver_url = config.get('urlresolver_url', None)
        self.secret_key = config.get('secret_key') or config.get('SECRET_KEY')
        self.prefix = config.get('current_prefix', 'a')
        self.action = config.get('action') or self.default_action
        self.links_limit = config.get('links_limit') or LINKS_LIMIT
        if not self.resolver_url:
            raise ImproperlyConfigured('Missed URL resolver url')
        resolver_parsed = urlparse(self.resolver_url)
        self.url_scheme = resolver_parsed.scheme
        self.url_netloc = resolver_parsed.netloc
        if not self.secret_key:
            raise ImproperlyConfigured('Missed secret key')
        self.encoder = AESEncoder(self.secret_key)

    async def process(self, message: MessageInfo, url_protection=None):
        if all(phase_conf is None
               for phase_name, phase_conf in url_protection.items()):
            return
        whitelist = self._compile_whitelist_rules(url_protection)

        rewrited_links = 0
        if message.email.is_multipart():
            for part in message.attachments:
                if part.is_body:
                    enc = encoding_aliases(
                        part.attach.get_content_charset(), failobj='utf-8')
                    ct = part.attach.get_content_type()
                    cte = str(part.attach.get(
                        'content-transfer-encoding', '')).lower()
                    payload = part.attach.get_payload(decode=True)
                    try:
                        payload, rewrited = \
                            await self._process_payload(payload, whitelist,
                                                        enc, ct, cte)
                        if rewrited:
                            part.set_payload(payload)
                            rewrited_links += rewrited
                    except LinksLimitExceeded:
                        txt = 'Links limit exceeded: %s' % self.links_limit
                        self.apply_action(message, self.action, reason=txt)

        elif len(message.attachments) == 0:
            enc = encoding_aliases(
                message.email.get_content_charset(), failobj='utf-8')
            ct = message.email.get_content_type()
            cte = str(message.email.get(
                'content-transfer-encoding', '')).lower()
            payload = message.email.get_payload(decode=True)
            try:
                payload, rewrited_links = \
                    await self._process_payload(payload, whitelist,
                                                enc, ct, cte)
            except LinksLimitExceeded:
                txt = 'Links limit exceeded: %s' % self.links_limit
                self.apply_action(message, self.action, reason=txt)
            if rewrited_links:
                message.email.set_payload(payload)
        if rewrited_links:
            return 'links: ' + str(rewrited_links)

    async def _process_payload(self, payload, whitelist, enc, ct, cte):

        rewrited = 0
        has_surrogates = False
        if ct == 'text/plain':
            searcher_cls = PlainTextSearcher
        elif ct == 'text/html':
            searcher_cls = HtmlSearcher
        else:
            return payload, rewrited

        try:
            data = payload.decode(encoding=enc or 'utf-8',
                                  errors='strict')
        except UnicodeDecodeError:
            has_surrogates = True
            data = payload.decode(encoding='utf-8',
                                  errors='surrogateescape')

        rewrited_data, rewrited = self._rewrite(data, whitelist, searcher_cls)

        if not rewrited:
            return payload, rewrited

        if not has_surrogates:
            rewrited_payload = rewrited_data.encode(encoding=enc or 'utf-8',
                                                    errors='strict')
        else:
            rewrited_payload = rewrited_data.encode(encoding='utf-8',
                                                    errors='surrogateescape')

        if cte == 'base64':
            rewrited_payload = encode_b64(rewrited_payload)
        elif cte == 'quoted-printable':
            rewrited_payload = encode_q(rewrited_payload)
        elif cte in ('x-uuencode', 'uuencode', 'uue', 'x-uue'):
            rewrited_payload = encode_uu(rewrited_payload)

        return rewrited_payload, rewrited

    def _rewrite(self, data, whitelist, searcher_cls):
        matches = searcher_cls.collect_matches(data, self.links_limit)
        rewrited = 0
        if not matches:
            return '', rewrited
        parts = []
        last_pos = 0
        for url, parsed, start, end, quot in matches:
            if self._match(url, parsed, whitelist):
                continue
            parts.append(data[last_pos:start])
            last_pos = end
            parts.append(quot)
            parts.append(self._encode(url))
            parts.append(quot)
            rewrited += 1
        parts.append(data[last_pos:])
        return ''.join(parts), rewrited

    def _encode(self, url):
        return ''.join((
            self.url_scheme,
            '://',
            self.url_netloc,
            '/?',
            self.prefix,
            self.encoder.encode(url)
        ))

    @staticmethod
    def _match(url: str, parsed, whitelist) -> bool:
        authority = parsed.netloc
        if not authority:
            authority = parsed.path
            pos = authority.find('/')
            if pos >= 0:
                authority = authority[:pos]
        scheme = parsed.scheme
        # remove user info
        pos = authority.find('@')
        if pos >= 0:
            authority = authority[pos + 1:]
        # remove port
        pos = authority.find(':')
        if pos >= 0:
            authority = authority[:pos]
        # unquote %xx symbols if presented
        domain = unquote(authority)
        domain = domain.lower()
        if scheme:
            domain = "%s://%s" % (scheme, domain)
        for rule in whitelist:
            if rule.match(domain) or rule.match(url):
                return True
        return False

    def _compile_whitelist_rules(self, config):
        whitelist = []
        result = []
        for phase_conf in config.values():
            if not phase_conf:
                continue
            whitelist += phase_conf.get('white_list') or []
        for template in whitelist:
            result.append(template_to_expression(template))
        result.append(template_to_expression(self.resolver_url))
        return result

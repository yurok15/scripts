import re
import abc
from urllib.parse import urlparse, urljoin
import html


DOT_INSIDE = re.compile(r'\[?(([\w\d\s]+\.)[\w\d\s]+)\]?')


class LinksLimitExceeded(BaseException):
    pass


class BaseSearcher:
    __metaclass__ = abc.ABCMeta
    exp = None

    @classmethod
    @abc.abstractmethod
    def collect_matches(cls, data, links_limit):
        """
        Collect all non-overlapping of url matches.
        Used for async rewrites.

        Return list of tuples [(<url>, <startpos>, <endpos>)]

        """

    @staticmethod
    def check(url, relative=False):
        try:
            url.encode('utf-8', errors='strict')
        except UnicodeEncodeError:
            return None, False
        try:
            res = urlparse(url)
            path = res.path
        except ValueError:
            return None, False

        if not relative:
            valid = any([res.netloc, res.scheme, DOT_INSIDE.match(path)])
        else:
            valid = any([res.path, res.params, res.query, res.fragment]) \
                   and not (res.netloc or res.scheme)
        return res, valid


class PlainTextSearcher(BaseSearcher):
    exp = re.compile(
        r'\b('
        r'(?:((http)|(https)|(ftp)):(?:\/{1,3})|www\d{0,3}[.])'
        r'(?:[^\s()<>]|\(([^\s()<>]|(\([^\s()<>]+\)))*\))+'
        r'(?:'
        r'\(([^\s()<>]|(\([^\s()<>]+\)))*\)'
        r'|'
        r"""[^\s`!()\[\]{};:'".,<>?«»“”‘’]"""
        r')'
        r')',
        re.IGNORECASE,
    )

    @classmethod
    def collect_matches(cls, data, links_limit):
        matches = []
        for match in cls.exp.finditer(data):
            url = match.group()
            parsed, valid = cls.check(url)
            if not valid:
                continue
            matches.append((url, parsed, *match.span(), ''))
            if len(matches) >= links_limit:
                raise LinksLimitExceeded
        return matches


class HtmlSearcher(BaseSearcher):

    exp = re.compile(
        r'(?:<(?P<tag>(a)|(v:)|(base))[^>]+(xlink:)?href\s*=\s*)'
        r'(?P<value>('
        r'(?P<quot>'
        r'([\'\"])|(&apos;)|(&quot;)|(&grave;)|(&#x22;)|(&#x27;)|(&#x60;))'
        r'(?P<url>.+?)(?P=quot))|'
        r'((?P<unquoted>'
        r'[^\u0020\u0009\u000A\u000C\u000D\u0022\u0027\u003c\u003e\u0060]+))'
        r')(?:\s*[^>]*>)',
        re.IGNORECASE | re.DOTALL
    )
    spaces_exp = re.compile(r'\s')

    @classmethod
    def collect_matches(cls, data, links_limit):
        base = ''
        candidates = []
        for match in cls.exp.finditer(data):
            tag = match.group('tag')
            start, end = match.span('value')
            url = match.group('url')
            if url:
                quot = html.unescape(match.group('quot'))
            else:
                url = match.group('unquoted')
                quot = ''
            url = html.unescape(url)
            url = cls.spaces_exp.sub('', url)
            if tag == 'base':
                parsed, valid = cls.check(url)
                if valid:
                    base = url
                continue
            if url.startswith('mailto:'):
                continue
            if len(candidates) >= links_limit:
                raise LinksLimitExceeded
            candidates.append((url, start, end, quot))

        matches = []
        for url, start, end, quot in candidates:
            if base:
                parsed, valid = cls.check(url, relative=True)
                if valid:
                    url = urljoin(base, url)
            parsed, valid = cls.check(url)
            if not valid:
                continue
            matches.append((url, parsed, start, end, quot))
        return matches
